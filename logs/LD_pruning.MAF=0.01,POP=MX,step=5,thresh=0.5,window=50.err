Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	LD_pruning
	1

[Fri Sep 18 14:09:11 2020]
rule LD_pruning:
    input: output/PCA/MX/MX_0.01.eigenvec.var.evo
    output: output/pruned/MX/MX_0.01.50_5_0.5.DA.prune.in
    jobid: 0
    wildcards: POP=MX, MAF=0.01, window=50, step=5, thresh=0.5


        cut -f2,25 -d',' output/PCA/MX/MX_0.01.eigenvec.var.evo > all_ss.temp
	awk '$2 != "NA"' FS=',' all_ss.temp | cut -f1 -d',' > all_ss.snps #Pick only D/A SNPs and get rsID 
        plink         --noweb         --bfile ../../data/1kg/plink-files/files/ALL.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes         --extract all_ss.snps         --make-bed         --out all_ss_plink 
        plink         --bfile all_ss_plink         --indep-pairwise 50 5 0.5         --noweb         --out "output/pruned/MX/MX_0.01.50_5_0.5.DA"
	rm all_ss*
        
Warning: At least 2321351 duplicate IDs in --extract file.
[Fri Sep 18 14:13:31 2020]
Finished job 0.
1 of 1 steps (100%) done
