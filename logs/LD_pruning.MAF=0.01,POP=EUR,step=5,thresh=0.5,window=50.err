Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	LD_pruning
	1

[Sun Sep 20 20:55:52 2020]
rule LD_pruning:
    input: output/PCA/EUR/EUR_0.01.eigenvec.var.evo
    output: output/pruned/EUR/EUR_0.01.50_5_0.5.DA.prune.in
    jobid: 0
    wildcards: POP=EUR, MAF=0.01, window=50, step=5, thresh=0.5


        cut -f2,25 -d',' output/PCA/EUR/EUR_0.01.eigenvec.var.evo > all_ss_EUR.temp
	awk '$2 != "NA"' FS=',' all_ss_EUR.temp | cut -f1 -d',' > all_ss_EUR.snps #Pick only D/A SNPs and get rsID 
        plink         --noweb         --bfile ../../data/1kg/plink-files/files/ALL.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes         --extract all_ss_EUR.snps         --make-bed         --out all_ss_plink_EUR 
        plink         --bfile all_ss_plink_EUR         --indep-pairwise 50 5 0.5         --noweb         --out "output/pruned/EUR/EUR_0.01.50_5_0.5.DA"
	rm all_ss_EUR*
        
[Sun Sep 20 20:59:48 2020]
Finished job 0.
1 of 1 steps (100%) done
