Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	LD_pruning
	1	add_evo_info
	1	plot_loadings
	1	run_pca
	4

[Mon Sep 14 16:53:11 2020]
rule run_pca:
    input: 1kg_IDS/ALL.txt
    output: output/PCA/ALL/ALL_0.01.eigenvec.var
    jobid: 3
    wildcards: POP=ALL, MAF=0.01

[Mon Sep 14 16:58:04 2020]
Finished job 3.
1 of 4 steps (25%) done

[Mon Sep 14 16:58:05 2020]
rule add_evo_info:
    input: output/PCA/ALL/ALL_0.01.eigenvec.var
    output: output/PCA/ALL/ALL_0.01.eigenvec.var.evo
    jobid: 1
    wildcards: POP=ALL, MAF=0.01

[Mon Sep 14 17:02:42 2020]
Finished job 1.
2 of 4 steps (50%) done

[Mon Sep 14 17:02:42 2020]
rule LD_pruning:
    input: output/PCA/ALL/ALL_0.01.eigenvec.var.evo
    output: output/pruned/ALL/ALL_0.01.100_5_0.5.DA.prune.in
    jobid: 2
    wildcards: POP=ALL, MAF=0.01, window=100, step=5, thresh=0.5

[Mon Sep 14 17:05:35 2020]
Finished job 2.
3 of 4 steps (75%) done

[Mon Sep 14 17:05:35 2020]
rule plot_loadings:
    input: output/PCA/ALL/ALL_0.01.eigenvec.var.evo, output/pruned/ALL/ALL_0.01.100_5_0.5.DA.prune.in
    output: output/figures/ALL/ALL_0.01.100_5_0.5.png
    jobid: 0
    wildcards: POP=ALL, MAF=0.01, window=100, step=5, thresh=0.5

[Mon Sep 14 17:05:50 2020]
Finished job 0.
4 of 4 steps (100%) done
Complete log: /project2/jjberg/jgblanc/PCA/.snakemake/log/2020-09-14T165309.962933.snakemake.log
